{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wiz_of_OZ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codesamskaaraH/RNN/blob/main/Wiz_of_OZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C97azX31ardL"
      },
      "source": [
        "# !pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIymVyjiatQn"
      },
      "source": [
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset(\"pg19\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkN9k5kWdlPu"
      },
      "source": [
        "# Alice in wonderland book\n",
        "import requests\n",
        "content = requests.get(\"https://www.gutenberg.org/files/55/55-0.txt\").text\n",
        "with open(\"wonderful_wiz.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "  f.write(content)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0yJeEjeqSqC"
      },
      "source": [
        "with open('wonderful_wiz.txt') as f:\n",
        "    data = f.readlines()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAHHX7hRsBMP"
      },
      "source": [
        "s_line = data[3]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTzu8vxqsjEK"
      },
      "source": [
        "with open('wonderful_wiz_norm.txt','w',encoding=\"utf-8\") as f:\n",
        "    f.write(s_line + '/n')\n",
        "    for line in data:\n",
        "        f.write(line)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWrdSp5t9mjS",
        "outputId": "66b72e65-8c94-4222-e39c-073078fb77bb"
      },
      "source": [
        "print(content[:100])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ï»¿The Project Gutenberg eBook of The Wonderful Wizard of Oz, by L. Frank Baum\r\n",
            "\r\n",
            "This eBook is for \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqsJyIoRaw7n"
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsdH9TGKeDNg"
      },
      "source": [
        "sequence_length = 100\n",
        "batch_size = 128\n",
        "\n",
        "# dataset file path\n",
        "FILE_PATH = \"wonderful_wiz_norm.txt\"\n",
        "\n",
        "# read the data\n",
        "text = open(FILE_PATH, encoding=\"utf-8\").read()\n",
        "\n",
        "# remove caps, comment this code if you want uppercase characters as well\n",
        "text = text.lower()\n",
        "# remove punctuation\n",
        "text = text.translate(str.maketrans(\"\", \"\", punctuation))\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCEbn6ktuhML"
      },
      "source": [
        "def strip_non_ascii(string):\n",
        "    ''' Returns the string without non ASCII characters'''\n",
        "    stripped = (c for c in string if 0 < ord(c) < 127)\n",
        "    return ''.join(stripped)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tCuH9VCuiQA"
      },
      "source": [
        "text = strip_non_ascii(text)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GeIlMgk1eO_O",
        "outputId": "8e7716d8-0bfa-45fb-83ba-03b200661fe3"
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'most other parts of the world at no cost and with almost no restrictions\\nnthe project gutenberg eboo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdJaCXfneamd",
        "outputId": "6d11d4f2-a08d-4559-e94a-ad24cce7a0a3"
      },
      "source": [
        "# print some stats\n",
        "n_chars = len(text)\n",
        "vocab = ''.join(sorted(set(text)))\n",
        "print(\"unique_chars:\", vocab)\n",
        "n_unique_chars = len(vocab)\n",
        "print(\"Number of characters:\", n_chars)\n",
        "print(\"Number of unique characters:\", n_unique_chars)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique_chars: \n",
            " 0123456789abcdefghijklmnopqrstuvwxyz\n",
            "Number of characters: 218948\n",
            "Number of unique characters: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esr1x34k7xTU",
        "outputId": "57eb8a03-a864-4991-ab20-52ce2ab71836"
      },
      "source": [
        "print('\\ufeff')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4waTOoVdelhw",
        "outputId": "23434842-c61a-4d82-cc2f-f08688c1378e"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n 0123456789abcdefghijklmnopqrstuvwxyz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzM_cwMb79m0",
        "outputId": "e12bcfd8-ccee-4eca-f726-5ff3bc4aaed0"
      },
      "source": [
        "for i, c in enumerate(\"abc\"):\n",
        "  print(i, c)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 a\n",
            "1 b\n",
            "2 c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdWD3_Q2em6X"
      },
      "source": [
        "# dictionary that converts characters to integers\n",
        "char2int = {c: i for i, c in enumerate(vocab)}\n",
        "# dictionary that converts integers to characters\n",
        "int2char = {i: c for i, c in enumerate(vocab)}"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_S3OHxd-HDW",
        "outputId": "a1330dc7-b05a-41f2-d749-d96db8e264fe"
      },
      "source": [
        "print(char2int)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz-u8vSYDpYm",
        "outputId": "e3390c9f-6b64-4764-cbce-3b924b8cf98f"
      },
      "source": [
        "print(int2char)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: '\\n', 1: ' ', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9', 12: 'a', 13: 'b', 14: 'c', 15: 'd', 16: 'e', 17: 'f', 18: 'g', 19: 'h', 20: 'i', 21: 'j', 22: 'k', 23: 'l', 24: 'm', 25: 'n', 26: 'o', 27: 'p', 28: 'q', 29: 'r', 30: 's', 31: 't', 32: 'u', 33: 'v', 34: 'w', 35: 'x', 36: 'y', 37: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "5fT_3VVh8jzN",
        "outputId": "257281b1-e8ac-4be6-af5d-9c26df30f9b0"
      },
      "source": [
        "text[5000:6000]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ys merry voice reached\\nher ears and she still looked at the little girl with wonder that she\\ncould find anything to laugh at\\n\\nuncle henry never laughed he worked hard from morning till night and\\ndid not know what joy was he was gray also from his long beard to his\\nrough boots and he looked stern and solemn and rarely spoke\\n\\nit was toto that made dorothy laugh and saved her from growing as gray\\nas her other surroundings toto was not gray he was a little black\\ndog with long silky hair and small black eyes that twinkled merrily on\\neither side of his funny wee nose toto played all day long and\\ndorothy played with him and loved him dearly\\n\\ntoday however they were not playing uncle henry sat upon the\\ndoorstep and looked anxiously at the sky which was even grayer than\\nusual dorothy stood in the door with toto in her arms and looked at\\nthe sky too aunt em was washing the dishes\\n\\nfrom the far north they heard a low wail of the wind and uncle henry\\nand dorothy could see where the long grass bowe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeKnnrxqetEt"
      },
      "source": [
        "# convert all text into integers\n",
        "encoded_text = np.array([char2int[c] for c in text])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob-_BdxW-OtY",
        "outputId": "b4ae1032-186c-4c65-ce96-da15b901b52f"
      },
      "source": [
        "len(encoded_text), len(text)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218948, 218948)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y-N6wH2jD92P",
        "outputId": "95b815c6-2611-41c2-900c-c8e98c4477d7"
      },
      "source": [
        "text[:25]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'most other parts of the w'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsCZv9Uce33c",
        "outputId": "03ebf4a1-95e4-47fb-e4c4-5811798d1fdd"
      },
      "source": [
        "encoded_text[:25]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24, 26, 30, 31,  1, 26, 31, 19, 16, 29,  1, 27, 12, 29, 31, 30,  1,\n",
              "       26, 17,  1, 31, 19, 16,  1, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr6hFCtlfpn3"
      },
      "source": [
        "# tokenize  input_seq, target_seq\n",
        "def create_sequence_data(text, sequence_length):\n",
        "  input_seq = []\n",
        "  target_seq = []\n",
        "  for idx in range(0, len(text), sequence_length):\n",
        "    st_idx = idx\n",
        "    end_idx = st_idx + sequence_length + 1\n",
        "    if end_idx > len(text):\n",
        "      # Exclude last slice that may not be full\n",
        "      continue\n",
        "    input_seq.append(text[st_idx:end_idx-1])\n",
        "    target_seq.append(text[st_idx+1:end_idx])\n",
        "  return input_seq, target_seq"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwX-jPEyglZk"
      },
      "source": [
        "input_seq, target_seq = create_sequence_data(encoded_text, sequence_length=sequence_length)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOQkaSlngzkU",
        "outputId": "4960308c-f628-49a4-bcc3-337aabe50438"
      },
      "source": [
        "input_seq[0:3]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([24, 26, 30, 31,  1, 26, 31, 19, 16, 29,  1, 27, 12, 29, 31, 30,  1,\n",
              "        26, 17,  1, 31, 19, 16,  1, 34, 26, 29, 23, 15,  1, 12, 31,  1, 25,\n",
              "        26,  1, 14, 26, 30, 31,  1, 12, 25, 15,  1, 34, 20, 31, 19,  1, 12,\n",
              "        23, 24, 26, 30, 31,  1, 25, 26,  1, 29, 16, 30, 31, 29, 20, 14, 31,\n",
              "        20, 26, 25, 30,  0, 25, 31, 19, 16,  1, 27, 29, 26, 21, 16, 14, 31,\n",
              "         1, 18, 32, 31, 16, 25, 13, 16, 29, 18,  1, 16, 13, 26, 26]),\n",
              " array([22,  1, 26, 17,  1, 31, 19, 16,  1, 34, 26, 25, 15, 16, 29, 17, 32,\n",
              "        23,  1, 34, 20, 37, 12, 29, 15,  1, 26, 17,  1, 26, 37,  1, 13, 36,\n",
              "         1, 23,  1, 17, 29, 12, 25, 22,  1, 13, 12, 32, 24,  0,  0, 31, 19,\n",
              "        20, 30,  1, 16, 13, 26, 26, 22,  1, 20, 30,  1, 17, 26, 29,  1, 31,\n",
              "        19, 16,  1, 32, 30, 16,  1, 26, 17,  1, 12, 25, 36, 26, 25, 16,  1,\n",
              "        12, 25, 36, 34, 19, 16, 29, 16,  1, 20, 25,  1, 31, 19, 16]),\n",
              " array([ 1, 32, 25, 20, 31, 16, 15,  1, 30, 31, 12, 31, 16, 30,  1, 12, 25,\n",
              "        15,  0, 24, 26, 30, 31,  1, 26, 31, 19, 16, 29,  1, 27, 12, 29, 31,\n",
              "        30,  1, 26, 17,  1, 31, 19, 16,  1, 34, 26, 29, 23, 15,  1, 12, 31,\n",
              "         1, 25, 26,  1, 14, 26, 30, 31,  1, 12, 25, 15,  1, 34, 20, 31, 19,\n",
              "         1, 12, 23, 24, 26, 30, 31,  1, 25, 26,  1, 29, 16, 30, 31, 29, 20,\n",
              "        14, 31, 20, 26, 25, 30,  0, 34, 19, 12, 31, 30, 26, 16, 33])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cERECQ3zhq51",
        "outputId": "c50120cd-c02e-425d-e59a-be51765ee39a"
      },
      "source": [
        "target_seq[0:3]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([26, 30, 31,  1, 26, 31, 19, 16, 29,  1, 27, 12, 29, 31, 30,  1, 26,\n",
              "        17,  1, 31, 19, 16,  1, 34, 26, 29, 23, 15,  1, 12, 31,  1, 25, 26,\n",
              "         1, 14, 26, 30, 31,  1, 12, 25, 15,  1, 34, 20, 31, 19,  1, 12, 23,\n",
              "        24, 26, 30, 31,  1, 25, 26,  1, 29, 16, 30, 31, 29, 20, 14, 31, 20,\n",
              "        26, 25, 30,  0, 25, 31, 19, 16,  1, 27, 29, 26, 21, 16, 14, 31,  1,\n",
              "        18, 32, 31, 16, 25, 13, 16, 29, 18,  1, 16, 13, 26, 26, 22]),\n",
              " array([ 1, 26, 17,  1, 31, 19, 16,  1, 34, 26, 25, 15, 16, 29, 17, 32, 23,\n",
              "         1, 34, 20, 37, 12, 29, 15,  1, 26, 17,  1, 26, 37,  1, 13, 36,  1,\n",
              "        23,  1, 17, 29, 12, 25, 22,  1, 13, 12, 32, 24,  0,  0, 31, 19, 20,\n",
              "        30,  1, 16, 13, 26, 26, 22,  1, 20, 30,  1, 17, 26, 29,  1, 31, 19,\n",
              "        16,  1, 32, 30, 16,  1, 26, 17,  1, 12, 25, 36, 26, 25, 16,  1, 12,\n",
              "        25, 36, 34, 19, 16, 29, 16,  1, 20, 25,  1, 31, 19, 16,  1]),\n",
              " array([32, 25, 20, 31, 16, 15,  1, 30, 31, 12, 31, 16, 30,  1, 12, 25, 15,\n",
              "         0, 24, 26, 30, 31,  1, 26, 31, 19, 16, 29,  1, 27, 12, 29, 31, 30,\n",
              "         1, 26, 17,  1, 31, 19, 16,  1, 34, 26, 29, 23, 15,  1, 12, 31,  1,\n",
              "        25, 26,  1, 14, 26, 30, 31,  1, 12, 25, 15,  1, 34, 20, 31, 19,  1,\n",
              "        12, 23, 24, 26, 30, 31,  1, 25, 26,  1, 29, 16, 30, 31, 29, 20, 14,\n",
              "        31, 20, 26, 25, 30,  0, 34, 19, 12, 31, 30, 26, 16, 33, 16])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPv0qTjHirh_"
      },
      "source": [
        "train_seq, valid_seq, train_targets, valid_targets = train_test_split(input_seq, target_seq, test_size=0.1)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wnqnye7Ri-ow",
        "outputId": "cab936df-5358-4305-fe5c-335ec41b0f70"
      },
      "source": [
        "len(train_seq), len(valid_seq)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1970, 219)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d4fxg74e4xE"
      },
      "source": [
        "def one_hot_encode(sequence, vocab_size):\n",
        "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
        "    # (Sequence Length, One-Hot Encoding Size)\n",
        "    seq_length = len(sequence)\n",
        "    output = np.zeros((seq_length, vocab_size), dtype=np.float32)\n",
        "\n",
        "    for seq in range(seq_length):\n",
        "      output[seq, sequence[seq]] = 1\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzoc-ue3FEri",
        "outputId": "8b06ab9a-6bd2-4f11-f55c-13f7ed1acc8b"
      },
      "source": [
        "one_hot_encode([1, 2, 26], len(vocab)).shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIJueFMffPZd"
      },
      "source": [
        "class TextGenDataset(Dataset):\n",
        "  def __init__(self, text_seq, target_seq, seq_length, vocab_size):\n",
        "    super().__init__()\n",
        "    self.text_seq = text_seq\n",
        "    self.target_seq = target_seq\n",
        "    self.seq_length = seq_length\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return one_hot_encode(self.text_seq[idx], self.vocab_size), self.target_seq[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text_seq)\n",
        "\n",
        "train_ds = TextGenDataset(train_seq, train_targets, sequence_length, len(vocab))\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "valid_ds = TextGenDataset(valid_seq, valid_targets, sequence_length, len(vocab))\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size, drop_last=True)\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lvvw0FEA3Ri",
        "outputId": "807d04f4-0e2b-49c0-f745-d76116e3f960"
      },
      "source": [
        "x, y = train_ds[0]\n",
        "x.shape, y.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 38), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYtNiMVrBONr",
        "outputId": "80c302bc-f8b9-4d0d-a139-6d21bf275f73"
      },
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[17 29 26 24  1 13 16 19 20 25 15  1 31 19 16 24  1 31 19 16 36  1 31 32\n",
            " 29 25 16 15  1 12 25 15  1 34 12 23 22 16 15  1 31 19 29 26 32 18 19  1\n",
            " 31 19 16  1 17 26 29 16 30 31  1 12  1 17 16 34  0 30 31 16 27 30  1 34\n",
            " 19 16 25  1 15 26 29 26 31 19 36  1 15 20 30 14 26 33 16 29 16 15  1 30\n",
            " 26 24 16 31]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBr-cqWalkDk"
      },
      "source": [
        "for x, y in train_dl:\n",
        "  break"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi6J04-olocP",
        "outputId": "39a9bb1a-bc48-4e4b-8f8e-16232133dc61"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 100, 38]), torch.Size([128, 100]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efF5E65pxV6m",
        "outputId": "2e626214-dabd-412e-a30e-9bb6f58cdbcd"
      },
      "source": [
        "print(x[0][2])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGU6C1Xhxglt"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x, hidden=None):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden.detach()"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleaPOjHyxWv"
      },
      "source": [
        "\n",
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=len(vocab), output_size=len(vocab), hidden_dim=512, n_layers=3)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 100\n",
        "lr=0.001\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcqYWw2uzHa7"
      },
      "source": [
        "# Training Run\n",
        "def train(model, train_dl, criterion, optimizer, batch_size, device=None, n_epochs=100):\n",
        "  if device is None:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  criterion = criterion.to(device)\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    hidden = None\n",
        "    n_batches = 0\n",
        "    losses = 0\n",
        "    for input_seq, target_seq in train_dl:\n",
        "      input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
        "      optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
        "      output, hidden = model(input_seq, hidden)\n",
        "      loss = criterion(output, target_seq.view(-1).long())\n",
        "      loss.backward() # Does backpropagation and calculates gradients\n",
        "      optimizer.step() # Updates the weights accordingly\n",
        "      # hidden.detach_()\n",
        "      losses += loss.item()\n",
        "      n_batches += 1\n",
        "    \n",
        "    if epoch%10 == 0:\n",
        "      print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "      print(\"Loss: {:.4f}\".format(losses / n_batches))\n",
        "  return model"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKmXZ1Xm0Ljf",
        "outputId": "c8a0cfb4-65d5-492e-bcb9-6aa928f213c2"
      },
      "source": [
        "model = train(model, train_dl, criterion, optimizer, batch_size, device, n_epochs=200)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10/200............. Loss: 1.8126\n",
            "Epoch: 20/200............. Loss: 1.2848\n",
            "Epoch: 30/200............. Loss: 1.0706\n",
            "Epoch: 40/200............. Loss: 0.9242\n",
            "Epoch: 50/200............. Loss: 0.7577\n",
            "Epoch: 60/200............. Loss: 0.6117\n",
            "Epoch: 70/200............. Loss: 0.5762\n",
            "Epoch: 80/200............. Loss: 0.4005\n",
            "Epoch: 90/200............. Loss: 0.3482\n",
            "Epoch: 100/200............. Loss: 0.2285\n",
            "Epoch: 110/200............. Loss: 0.2168\n",
            "Epoch: 120/200............. Loss: 0.1130\n",
            "Epoch: 130/200............. Loss: 0.0646\n",
            "Epoch: 140/200............. Loss: 0.0340\n",
            "Epoch: 150/200............. Loss: 0.0205\n",
            "Epoch: 160/200............. Loss: 0.0107\n",
            "Epoch: 170/200............. Loss: 0.0086\n",
            "Epoch: 180/200............. Loss: 0.0072\n",
            "Epoch: 190/200............. Loss: 0.0062\n",
            "Epoch: 200/200............. Loss: 0.0054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B16JMDUcEgcU"
      },
      "source": [
        "#model.load_state_dict(torch.load(\"model.pt\"))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUSYJ0XCieXZ"
      },
      "source": [
        "def predict(model, hidden, character, char2int, int2char, device):  \n",
        "    # One-hot encoding our input to fit into the model\n",
        "    # print(character)\n",
        "    character = np.array([char2int[c] for c in character])\n",
        "    # print(character)\n",
        "    character = one_hot_encode(character, vocab_size=len(char2int))\n",
        "    # print(character.shape)\n",
        "    character = torch.from_numpy(character).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      out, hidden = model(character, hidden)\n",
        "    # print(hidden.size())\n",
        "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
        "    # Taking the class with the highest probability score from the output\n",
        "    char_ind = torch.max(prob, dim=0)[1].item()\n",
        "\n",
        "    return int2char[char_ind], hidden"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHWhLyodjzfm"
      },
      "source": [
        "def sample(model, char2int, int2char, out_len, start='hey', device=None):\n",
        "    model.eval() # eval mode\n",
        "    if device is None:\n",
        "      device = \"cuda\" if torch.cuda.is_available() else \"cpu\"    \n",
        "    model.to(device)\n",
        "    start = start.lower()\n",
        "    # First off, run through the starting characters\n",
        "    chars = [ch for ch in start]\n",
        "    size = out_len - len(chars)\n",
        "    # Now pass in the previous characters and get a new one\n",
        "    hidden = None\n",
        "    for ii in range(size):\n",
        "        # print(chars)\n",
        "        char, hidden = predict(model, hidden, chars[-1], char2int, int2char, device)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ffotnsvaljzy",
        "outputId": "4a6ab44b-623c-47b1-c638-28febc33eb39"
      },
      "source": [
        "sample(model, char2int, int2char, out_len=150, start=\"Oh gracious\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'oh graciousend me back to kansas\\n\\nwhere is the emerald city he inquired and who is oz\\n\\nwhy dont you know she returned and at once the winged monkeys\\nc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nt060BMVjC-T",
        "outputId": "835ca44d-54ef-43f6-9f89-4c962c3477a6"
      },
      "source": [
        "#whirlwinds arose\n",
        "sample(model, char2int, int2char, out_len=150, start=\"whirlwinds arose\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'whirlwinds arosed t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind t\\nmind'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jykAcuecwA7",
        "outputId": "1c04c7bd-828d-4960-c76d-75014e3b37aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample(model, char2int, int2char, out_len=150, start=\"Uncle Henry\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'uncle henry around her but dorothy\\nfound she was riding quite easily after the field mice and how they had generously saved\\nhim from death and the cow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NmvV3WfiSid"
      },
      "source": [
        "torch.save(model.state_dict(), \"./model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1HwxC7Xj541"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}